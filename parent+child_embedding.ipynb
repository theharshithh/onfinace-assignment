{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theharshithh/onfinace-assignment/blob/main/parent%2Bchild_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cA__z7w124oE"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E16GzrTO24oF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bbb1a25-4dbb-4503-d62e-7d0c55a69e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q --quiet install langchain openai tiktoken chromadb langchain_openai cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain_experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH8K5KVxo5A-",
        "outputId": "a47b9ab7-55c8-4cf4-d727-32b6f7a9ea85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/193.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/193.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m184.3/193.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aC_PvcOz24oG"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "# from langchain_cohere import CohereEmbeddings\n",
        "import cohere\n",
        "from google.colab import userdata\n",
        "cohere_api_key = userdata.get('COHERE_API_KEY')\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "co = cohere.Client(cohere_api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_loader = PyPDFLoader('dataset/sample_data.pdf')\n",
        "docs = file_loader.load()\n",
        "docs"
      ],
      "metadata": {
        "id": "Z1ax0E2Y05IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHIxTEVm24oG"
      },
      "source": [
        "loading data to /dataset dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet install pypdf"
      ],
      "metadata": {
        "id": "SaT9Zf4W4hy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPppZ8Nc24oH"
      },
      "source": [
        "creating chunks for the `primary_data`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "primary_data = docs\n",
        "primary_data\n",
        "\n",
        "\n",
        "# primary_data = [doc.page_content for doc in docs]"
      ],
      "metadata": {
        "id": "1Jr1Wrk8YUet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "h-1iqLhz24oH"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'db-trash'\n",
        "\n",
        "#openai embeddings -> converts texts to vecs\n",
        "embedding = OpenAIEmbeddings(openai_api_key = openai_api_key)\n",
        "# embedding = OpenAIEmbeddings(openai_api_key = openai_api_key, model=\"text-embedding-3-small\")\n",
        "\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=spilit_texts, embedding=embedding, persist_directory=persist_directory)\n",
        "vectordb.persist()\n",
        "vectordb = None\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvH_lysS24oI",
        "outputId": "7de5b451-b3fa-427d-afff-c609d370c459"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\" Automobiles  \\n27 March 2023    3 \\nSnapshot of Mar ’23 volume estimates                \\n  YoY     MoM        \\nCompany Sales  Mar -23 Mar -22 YoY (%)  \\n chg Feb-23 MoM (%) \\nchg FY23E  FY22  (%) \\n chg \\nMaruti Suzuki  1,64,812  1,70,395  -3.3 1,72,321  -4.4 19,60,905  16,52,653  18.7  \\nLCVs  3,887  3,797  2.4 3,356  15.8  37,869  33,812  12.0  \\nVans  11,901  9,221  29.1  11,352  4.8 1,31,097  1,08,345  21.0  \\nMini Segment  20,020  15,491  29.2  21,875  -8.5 2,41,349  2,11,762  14.0  \\nCompact (incl Dzire Tour)  74,673  84,761  -11.9  81,325  -8.2 8,95,245  7,26,443  23.2  \\nMid-Size - CIAZ  972 1,834  -47.0  792 22.7  14,282  15,869  -10.0  \\nUVs 36,931  28,795  28.3  36,414  1.4 3,95,421  3,18,046  24.3  \\nDomestic  1,48,385  1,43,899  3.1 1,55,114  -4.3 17,15,264  14,14,277  21.3  \\nExport  16,427  26,496  -38.0  17,207  -4.5 2,45,641  2,38,376  3.0 \\nMahindra & Mahindra  94,804  84,406  12.3  84,592  12.1  10,99,710  8,20,299  34.1  \\n   UV (incl. pick -ups)  57,637  49,771  15.8  52,364  10.1  6,28,612  4,29,087  46.5  \\n   LCV & M&HCV  833 829 0.5 1,087  -23.3  9,410  6,435  46.2  \\n   Three -Wheelers  6,282  4,043  55.4  5,350  17.4  59,105  30,079  96.5  \\n   Tractors  30,051  29,763  1.0 25,791  16.5  4,02,582  3,54,698  13.5  \\nTata Motors  87,709  86,561  1.3 79,705  10.0  9,51,287  7,26,191  31.0  \\n   HCV's  22,589  23,238  -2.8 17,928  26.0  1,78,195  1,44,500  23.3  \\n   LCV's  21,485  20,855  3.0 18,637  15.3  2,32,595  2,09,515  11.0  \\n   CV's  44,074  44,093  0.0 36,565  20.5  4,10,790  3,54,015  16.0  \\n   Cars  14,463  14,369  0.7 14,344  0.8 1,77,165  1,44,670  22.5  \\n   UV's  29,171  28,099  3.8 28,796  1.3 3,63,332  2,27,506  59.7  \\nHero MotoCorp  4,34,165  4,50,170  -3.6 3,94,460  10.1  52,43,369  49,44,148  6.1 \\nBajaj Auto  2,81,922  2,97,188  -5.1 2,80,226  0.6 39,16,077  43,08,433  -9.1 \\n  Two -Wheelers  2,33,703  2,56,324  -8.8 2,35,356  -0.7 34,27,405  38,36,856  -10.7  \\n  Three -Wheelers  48,219  40,864  18.0  44,870  7.5 4,88,672  4,71,577  3.6 \\nDomestic  1,64,775  1,26,752  30.0  1,53,291  7.5 20,82,735  18,01,807  15.6  \\nExports  1,17,146  1,70,436  -31.3  1,26,935  -7.7 18,33,341  25,06,626  -26.9  \\nAshok Leyland  20,894  20,123  3.8 18,571  12.5  1,89,173  1,28,326  47.4  \\nM&HCV  14,197  13,990  1.5 12,668  12.1  1,21,533  73,885  64.5  \\nLCV  6,697  6,133  9.2 5,903  13.5  67,640  54,441  24 \\nTVS Motor  2,92,177  3,07,954  -5.1 2,76,150  5.8 36,57,093  33,09,578  10.5  \\nMotorcycles  1,37,970  1,60,522  -14.0  1,26,243  9.3 17,29,976  17,31,459  -0.1 \\nScooters  1,05,785  94,747  11.6  1,04,825  0.9 12,97,275  9,21,939  40.7  \\nMopeds  38,352  37,649  1.9 35,958  6.7 4,60,251  4,84,305  -5.0 \\nThree -Wheelers  10,070  15,036  -33.0  9,124  10.4  1,69,591  1,71,875  -1.3 \\nDomestic  2,35,861  1,98,230  19.0  2,22,745  5.9 26,07,757  20,56,387  26.8  \\nExports  56,315  1,09,724  -48.7  53,405  5.4 10,49,335  12,53,191  -16.3  \\nEicher Motors          Royal Enfield  74,155  67,670  9.6 71,544  3.6 8,36,815  6,02,268  38.9  \\nVECV  9,125  8,793  3.8 7,289  25.2  76,821  57,067  34.6  \\nEscorts Kubota  10,195  10,074  1.2 7,811  30.5  1,03,180  94,228  9.5 \\n \\n  \", metadata={'source': 'dataset/sample_data.pdf', 'page': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "\n",
        "# Use your trash data retriever to get the relevant documents\n",
        "trash_retriever = vectordb.as_retriever(search_kwargs={\"k\":20}) #k: 20 for more context window to llm\n",
        "trash_text = trash_retriever.get_relevant_documents('Get me the SEBI disclosure and the unnecessary disclaimers and terms and conditions')\n",
        "\n",
        "trash_metadata = [doc.metadata for doc in trash_text]\n",
        "main_data_filtered = [doc for doc in primary_data if doc.metadata not in trash_metadata]\n",
        "\n",
        "main_data_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "\n",
        "parents_vectordb = Chroma(\n",
        "    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        ")\n",
        "\n",
        "# memory to store the parent layer.\n",
        "store = InMemoryStore()"
      ],
      "metadata": {
        "id": "AGnKUSKOlnP4"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_vectordb = Chroma(\n",
        "    collection_name=\"full_documents\",\n",
        "    embedding_function= OpenAIEmbeddings(openai_api_key = openai_api_key)\n",
        ")\n",
        "\n",
        "store = InMemoryStore()\n",
        "\n",
        "full_doc_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = full_vectordb,\n",
        "    docstore = store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ],
      "metadata": {
        "id": "qMFFJBlqlwcx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_doc_retriever.add_documents(main_data_filtered, ids=None)"
      ],
      "metadata": {
        "id": "Gp_RFORKs1Y2"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(store.yield_keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjl3gR3w3f30",
        "outputId": "1a2a1afe-f8ea-4858-b3f0-070a9834a6c2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['60fbce9a-7dc2-4305-80a2-1e98ed622fb0',\n",
              " 'a34e1346-106c-48b5-9a96-9670922ac76d']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = 'Based on the current 2 wheeler demand, who is the market leader?'"
      ],
      "metadata": {
        "id": "qHnNzT9e3xAH"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_docs = vectordb.similarity_search(user_query)\n",
        "sub_docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "56Ck1CJN3lWi",
        "outputId": "d13e1dbd-7792-48b7-edb5-0d6e799a3dd4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hero MotoCorp  4,34,165  4,50,170  -3.6 3,94,460  10.1  52,43,369  49,44,148  6.1 \\nBajaj Auto  2,81,922  2,97,188  -5.1 2,80,226  0.6 39,16,077  43,08,433  -9.1 \\n  Two -Wheelers  2,33,703  2,56,324  -8.8 2,35,356  -0.7 34,27,405  38,36,856  -10.7  \\n  Three -Wheelers  48,219  40,864  18.0  44,870  7.5 4,88,672  4,71,577  3.6'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrived_docs = full_doc_retriever.get_relevant_documents(user_query)\n",
        "retrived_docs"
      ],
      "metadata": {
        "id": "UPGToVP141cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\":8}) #k: 20 for more context window to llm\n",
        "docs = retriever.get_relevant_documents(user_query)\n",
        "docs"
      ],
      "metadata": {
        "id": "TbM0V1bwtTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KscvzPA24oI"
      },
      "source": [
        "### LLM chain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere\n",
        "\n",
        "compressor = CohereRerank(cohere_api_key = cohere_api_key, model = 'rerank-english-v3.0') #   top_n = 3 -> can limit the sources\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever,\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
        "compressed_docs"
      ],
      "metadata": {
        "id": "bLXvrhSuZXlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "6MSnUSES24oI"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer question\n",
        "qa_chain_compressed = RetrievalQA.from_chain_type(llm=ChatOpenAI(openai_api_key=openai_api_key,model=\"gpt-3.5-turbo\", temperature=1.2 ), chain_type=\"stuff\", retriever=compression_retriever, return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer question\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(openai_api_key=openai_api_key,model=\"gpt-3.5-turbo\", temperature=1.2 ), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
      ],
      "metadata": {
        "id": "UIJwe8FXgMoV"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "lpGoJ7qn24oI"
      },
      "outputs": [],
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(\"Decision:\")\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    print(\"\\n Source Documents:\")\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(\"- \" + source.metadata['source'])\n",
        "\n",
        "    print(\"\\nRelevant Data:\")\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compressed qa chain for efficent retrival"
      ],
      "metadata": {
        "id": "moLHpJgTgWvH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoW-KIN724oI"
      },
      "outputs": [],
      "source": [
        "behaviour = '''Think like an expert finance consultant from a top tier firm. Do all the research and analysis for this document.'''\n",
        "prompt_template = 'Keep the answer crisp. Give me as much numbers as you can. Every Statement of yours should be backed with data'\n",
        "stop_prompt = f'Dont hallucinate, if u dont know the answer, tell you dont know'\n",
        "query = f\"Here is the user query : {user_query}. Remember this: {behaviour}. Give me the answers like this: {prompt_template}. Keep this in mind - {stop_prompt}\"\n",
        "llm_response = qa_chain_compressed(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "best version -> heavy credits burning -> deep pockets required"
      ],
      "metadata": {
        "id": "cQwFQmFDgpqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "Tg9soINRghE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain"
      ],
      "metadata": {
        "id": "bUVYCjQ-sA_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}